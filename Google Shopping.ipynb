{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Use Selenium to open webpages that use java script rendering ###############\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import time\n",
    "from urllib.request import Request, urlopen\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "####### Use Pandas to manage and arrange data #################\n",
    "import pandas as pd\n",
    "####### Use BeautifulSoup to read and navigate the DOM ################\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "######### Use Regex to clean up some of the elements we scrape #################\n",
    "import re\n",
    "############# Use Matplotlib to create and display a price graphs ################\n",
    "import matplotlib.pyplot as plt\n",
    "######### Use counter to count results of vendors ########\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## First ask user to input term to search Google Shopping ##########\n",
    "results = []\n",
    "pages = []\n",
    "allsellers = []\n",
    "terms = input('Enter serach term(s) here: ')\n",
    "terms = terms.split(', ')\n",
    "########## For each comma separated term retrieve first page results ##############\n",
    "for t in terms:\n",
    "    driver = webdriver.Chrome()\n",
    "    base = 'https://www.google.com/search?q='\n",
    "    shop = '&tbm=shop&tbs=vw:l'\n",
    "    url = base + t + shop\n",
    "    driver.implicitly_wait(30)\n",
    "    driver.get(url)\n",
    "    soup_level1=BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "\n",
    "\n",
    "    data = soup_level1.find_all('div', {'class':'mQ35Be'})\n",
    "    data1=[re.sub(r'<.+?>',r'',str(a)) for a in data]\n",
    "    data1=[re.sub(r'.*(stores).*',r'',str(a))for a in data1]\n",
    "    data1=[re.sub(r'.*(positive).*',r'',str(a))for a in data1]\n",
    "    data1=[x for x in data1 if x]\n",
    "    nearby='Also available nearby'\n",
    "    caturl=[re.sub(r' ',r'\\%20',str(a))for a in url]\n",
    "    caturl=''.join(caturl)\n",
    "    vendors = [re.sub(r'.*from',r'',str(a))for a in data1]\n",
    "    print('Search url : ' + caturl)\n",
    "    while nearby in data1:\n",
    "        data1.remove(nearby)\n",
    "    print(data1)\n",
    "    print(len(data1))\n",
    "\n",
    "    products=soup_level1.find_all('div', {'class':'eIuuYe'})\n",
    "    products=[re.sub(r'href=\"',r'\\^https://www.google.com',str(a)) for a in products]\n",
    "    products=[re.sub(r'.*\\^',r'',str(a)) for a in products]\n",
    "    products=[re.sub(r'\".*',r'',str(a)) for a in products]\n",
    "    products=[re.sub(r'.*(aclk).*',r'',str(a)) for a in products]\n",
    "    products=[re.sub(r'\\?.*',r'',str(a))for a in products]\n",
    "    products=[x for x in products if x]\n",
    "\n",
    "    results.append(data1)\n",
    "    pages.append(products)\n",
    "\n",
    "    driver.quit()\n",
    "############## For single listing sellers the Vendor name and price is returned. Grouped products are stored in a list of lists for each search term ################\n",
    "print(len(results))\n",
    "print(len(pages))\n",
    "print(len(pages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "########## Select the first set of grouped vendors from the search results ##########\n",
    "########## for each listing the vendors are counted, then Price, GTIN and Barcode are gathered ########\n",
    "for i in pages[0]:\n",
    "    url = i\n",
    "    page = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    title= soup.find('h1', {'id':'product-name'})\n",
    "    title=[re.sub(r'<.+?>',r'',str(a)) for a in title]\n",
    "    print(title)\n",
    "    table = soup.find_all('td', {'class':'os-seller-name'})\n",
    "    y=[re.sub(r'<.+?>',r'',str(a)) for a in table]\n",
    "    seller=len(y)\n",
    "    seller=str(seller)\n",
    "    print('Sellers : ' + seller)\n",
    "    print(url)\n",
    "    ######################### Rankings and Chart ######################\n",
    "\n",
    "    chart=pd.read_html(url)\n",
    "    chart=chart[2]\n",
    "    header=chart.iloc[0]\n",
    "    chart=chart[1:]\n",
    "\n",
    "    chart.columns = header\n",
    "\n",
    "    chart[['Total Price']]=chart[['Total Price']].replace('[\\$,]', '', regex=True).astype(float)\n",
    "    Sellers=chart.iloc[:,0:1]\n",
    "    Sellers=pd.DataFrame(Sellers)\n",
    "    Sellers=Sellers['Sellers'].tolist()\n",
    "    vendors.extend(Sellers)\n",
    "\n",
    "    Price=chart.iloc[:,4:]\n",
    "    Price=pd.DataFrame(Price)\n",
    "    Price=Price['Total Price'].tolist()\n",
    "    avg = chart['Total Price'].sum()\n",
    "    avgs = float(seller)\n",
    "    avg = float(avg)\n",
    "    avg = (avg/avgs)\n",
    "\n",
    "#     print(Price)\n",
    "    ##################### Create Price Visualization for PLA ##############################\n",
    "    ax = chart[['Sellers','Total Price']].plot(kind='barh', legend=True)\n",
    "\n",
    "    ax.set_ylabel('Seller')\n",
    "    ax.set_yticklabels(Sellers)\n",
    "    ax.set_xlabel('Cost')\n",
    "    ax.invert_yaxis()\n",
    "    for i, v in enumerate(Price):\n",
    "        ax.text(v + 3, i + .25, str(v), color='blue', fontweight='bold')\n",
    "\n",
    "    plt.show()\n",
    "    ##################### Look For Specifications in Listings ##############################\n",
    "\n",
    "    specs= url + '/specs'\n",
    "    table = pd.read_html(specs)\n",
    "    table=table[-1]\n",
    "    try:\n",
    "        mpn=table.loc[1,1]\n",
             mpn=str(mpn)\n",
    "    except KeyError:\n",
    "        mpn='--'\n",
    "\n",
    "    try:\n",
    "        GTIN=table.loc[1,1]\n",
    "        GTIN=str(GTIN)\n",
    "    except KeyError:\n",
    "        GTIN='--'\n",
    "    print('MPN : '+mpn+'   GTIN : '+GTIN)\n",
    "    print('')\n",
    "########################## Create Pie Graph of Seller's share of first page reuslts ##################\n",
    "print('PLA Share on First Page results for search term : '+terms[0])\n",
    "count=Counter(vendors)\n",
    "count=dict(count.most_common(10))\n",
    "# print(count.keys())\n",
    "labels=count.keys()\n",
    "sizes=count.values()\n",
    "plt.pie(sizes, labels=labels, shadow=True, autopct='%1.1f%%', startangle=45)\n",
    "plt.axis('equal')\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
